{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import mobilenet\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'img_fine_tuning/data/train'\n",
    "test_path = 'img_fine_tuning/data/test'\n",
    "valid_path = 'img_fine_tuning/data/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "Found 451 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    train_path, target_size=(224,224), batch_size=30)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    valid_path, target_size=(224,224), batch_size=30)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    test_path, target_size=(224,224), batch_size=30)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = base_model.get_layer('block5_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output = last_layer.output # (None, 7, 7, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(64, activation='relu', name='FC_2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(2, activation='softmax', name='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " FC_2 (Dense)                (None, 64)                1605696   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " softmax (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,320,770\n",
      "Trainable params: 16,320,642\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fkfma\\AppData\\Local\\Temp\\ipykernel_25388\\1404983144.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  new_model.fit_generator(train_batches, steps_per_epoch=4,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 60s - loss: 1.2399 - accuracy: 0.5089 - val_loss: 2.4894 - val_accuracy: 0.7167 - 60s/epoch - 15s/step\n",
      "Epoch 2/20\n",
      "4/4 - 1s - loss: 0.6553 - accuracy: 0.7321 - val_loss: 1.5360 - val_accuracy: 0.7167 - 1s/epoch - 308ms/step\n",
      "Epoch 3/20\n",
      "4/4 - 1s - loss: 0.4365 - accuracy: 0.8036 - val_loss: 0.9152 - val_accuracy: 0.7667 - 1s/epoch - 302ms/step\n",
      "Epoch 4/20\n",
      "4/4 - 1s - loss: 0.2701 - accuracy: 0.9107 - val_loss: 2.9953 - val_accuracy: 0.7000 - 1s/epoch - 302ms/step\n",
      "Epoch 5/20\n",
      "4/4 - 1s - loss: 0.2415 - accuracy: 0.9000 - val_loss: 3.5881 - val_accuracy: 0.6000 - 1s/epoch - 303ms/step\n",
      "Epoch 6/20\n",
      "4/4 - 1s - loss: 0.1497 - accuracy: 0.9464 - val_loss: 0.7997 - val_accuracy: 0.8333 - 1s/epoch - 274ms/step\n",
      "Epoch 7/20\n",
      "4/4 - 1s - loss: 0.1006 - accuracy: 0.9554 - val_loss: 0.6476 - val_accuracy: 0.8667 - 1s/epoch - 277ms/step\n",
      "Epoch 8/20\n",
      "4/4 - 1s - loss: 0.1548 - accuracy: 0.9417 - val_loss: 4.0903 - val_accuracy: 0.5167 - 1s/epoch - 291ms/step\n",
      "Epoch 9/20\n",
      "4/4 - 1s - loss: 0.1342 - accuracy: 0.9643 - val_loss: 0.8863 - val_accuracy: 0.8333 - 1s/epoch - 279ms/step\n",
      "Epoch 10/20\n",
      "4/4 - 1s - loss: 0.1137 - accuracy: 0.9643 - val_loss: 0.9518 - val_accuracy: 0.8333 - 1s/epoch - 278ms/step\n",
      "Epoch 11/20\n",
      "4/4 - 1s - loss: 0.0926 - accuracy: 0.9464 - val_loss: 0.4845 - val_accuracy: 0.8333 - 1s/epoch - 282ms/step\n",
      "Epoch 12/20\n",
      "4/4 - 1s - loss: 0.1047 - accuracy: 0.9732 - val_loss: 0.6419 - val_accuracy: 0.9000 - 1s/epoch - 278ms/step\n",
      "Epoch 13/20\n",
      "4/4 - 1s - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.8167 - 1s/epoch - 297ms/step\n",
      "Epoch 14/20\n",
      "4/4 - 1s - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8500 - 1s/epoch - 280ms/step\n",
      "Epoch 15/20\n",
      "4/4 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.8500 - 1s/epoch - 283ms/step\n",
      "Epoch 16/20\n",
      "4/4 - 1s - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9000 - 1s/epoch - 287ms/step\n",
      "Epoch 17/20\n",
      "4/4 - 1s - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8833 - 1s/epoch - 287ms/step\n",
      "Epoch 18/20\n",
      "4/4 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9000 - 1s/epoch - 281ms/step\n",
      "Epoch 19/20\n",
      "4/4 - 1s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9333 - 1s/epoch - 306ms/step\n",
      "Epoch 20/20\n",
      "4/4 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8667 - 1s/epoch - 274ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1984c7c2860>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit_generator(train_batches, steps_per_epoch=4,\n",
    "                   validation_data=valid_batches, validation_steps=2, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "# from tensorflow.keras.utils import np_utils 위 코드가 안될 수도 있는데 안되는 경우 이 코드로 대체.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    paths = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target'])) # 최신버전?에서는 경로가 바뀌어서 에러가 나올 수 있다고 함\n",
    "    return paths, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, test_targets = load_dataset('img_fine_tuning/data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [00:00<00:00, 624.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "test_tensors = preprocess_input(paths_to_tensor(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 106ms/step - loss: 0.4321 - accuracy: 0.8825\n",
      "\n",
      "Testing loss: 0.4321\n",
      "Testing accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*new_model.evaluate(test_tensors, test_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 74ms/step - loss: 0.4321 - accuracy: 0.8825\n",
      "\n",
      " Test accuracy: 0.8824833631515503\n"
     ]
    }
   ],
   "source": [
    "# evaluate and print test accuracy\n",
    "score = new_model.evaluate(test_tensors, test_targets)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "cat\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir('img_fine_tuning/data/train')\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"img_fine_tuning/data/train\")\n",
    "categories = []\n",
    "fn=[]\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category[:3] == 'dog':\n",
    "        categories.append(1)\n",
    "        fn.append(filename)\n",
    "\n",
    "    elif category[:3] == 'cat':\n",
    "        categories.append(0)\n",
    "        fn.append(filename)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'filename': fn,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  category\n",
       "0      cat         0\n",
       "1      dog         1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'img_fine_tuning/data/train/cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sample \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(fn)\n\u001b[1;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_fine_tuning/data/train/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "File \u001b[1;32mc:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    281\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:113\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# convert it to an 8-bit grayscale image.\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'img_fine_tuning/data/train/cat'"
     ]
    }
   ],
   "source": [
    "sample = random.choice(fn)\n",
    "image = load_img(\"img_fine_tuning/data/train/\"+sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,939,842\n",
      "Trainable params: 12,939,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename category\n",
       "0      dog      dog"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df #8\n",
    "validate_df #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0] #8\n",
    "total_validate = validate_df.shape[0] #2\n",
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    \"train/\",\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    \"train/\",\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename category\n",
       "0      cat      cat"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df,\n",
    "    \"train/\",\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m example_generator:\n\u001b[1;32m----> 5\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mX_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
