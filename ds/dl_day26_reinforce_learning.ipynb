{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hunkim.github.io/ml/\n",
    "# https://deeplearningzerotoall.github.io/season2/ 이건 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아타리 게임에 적용한 강화학습이 대표적인 케이스임"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 상태(s)에서 특정행동(a)을 취했을 때 가장 높은 값(maxQ)을 취할 수 있는 arguments를 구하는 것이 강화학습의 목표임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로보어드바이저를 만들 때 강화학습이 주로 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뭔가 에러남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "PhotoImage = ImageTk.PhotoImage\n",
    "UNIT = 50  # 픽셀 수\n",
    "HEIGHT = 5  # 그리드 세로\n",
    "WIDTH = 5  # 그리드 가로\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class Env(tk.Tk):\n",
    "    def __init__(self, render_speed=0.01):\n",
    "        super(Env, self).__init__()\n",
    "        self.render_speed=render_speed\n",
    "        self.action_space = ['u', 'd', 'l', 'r']\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.title('REINFORCE')\n",
    "        self.geometry('{0}x{1}'.format(HEIGHT * UNIT, HEIGHT * UNIT))\n",
    "        self.shapes = self.load_images()\n",
    "        self.canvas = self._build_canvas()\n",
    "        self.counter = 0\n",
    "        self.rewards = []\n",
    "        self.goal = []\n",
    "        # 장애물 설정\n",
    "        self.set_reward([0, 1], -1)\n",
    "        self.set_reward([1, 2], -1)\n",
    "        self.set_reward([2, 3], -1)\n",
    "        # 목표 지점 설정\n",
    "        self.set_reward([4, 4], 1)\n",
    "\n",
    "    def _build_canvas(self):\n",
    "        canvas = tk.Canvas(self, bg='white',\n",
    "                           height=HEIGHT * UNIT,\n",
    "                           width=WIDTH * UNIT)\n",
    "        # 그리드 생성\n",
    "        for c in range(0, WIDTH * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = c, 0, c, HEIGHT * UNIT\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "        for r in range(0, HEIGHT * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = 0, r, HEIGHT * UNIT, r\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "\n",
    "        self.rewards = []\n",
    "        self.goal = []\n",
    "        # 캔버스에 이미지 추가\n",
    "        x, y = UNIT/2, UNIT/2\n",
    "        self.rectangle = canvas.create_image(x, y, image=self.shapes[0])\n",
    "\n",
    "        canvas.pack()\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def load_images(self):\n",
    "        rectangle = PhotoImage(\n",
    "            Image.open(\"../img/rectangle.png\").resize((30, 30)))\n",
    "        triangle = PhotoImage(\n",
    "            Image.open(\"../img/triangle.png\").resize((30, 30)))\n",
    "        circle = PhotoImage(\n",
    "            Image.open(\"../img/circle.png\").resize((30, 30)))\n",
    "\n",
    "        return rectangle, triangle, circle\n",
    "\n",
    "    def reset_reward(self):\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            self.canvas.delete(reward['figure'])\n",
    "\n",
    "        self.rewards.clear()\n",
    "        self.goal.clear()\n",
    "        self.set_reward([0, 1], -1)\n",
    "        self.set_reward([1, 2], -1)\n",
    "        self.set_reward([2, 3], -1)\n",
    "\n",
    "        # #goal\n",
    "        self.set_reward([4, 4], 1)\n",
    "\n",
    "    def set_reward(self, state, reward):\n",
    "        state = [int(state[0]), int(state[1])]\n",
    "        x = int(state[0])\n",
    "        y = int(state[1])\n",
    "        temp = {}\n",
    "        if reward > 0:\n",
    "            temp['reward'] = reward\n",
    "            temp['figure'] = self.canvas.create_image((UNIT * x) + UNIT / 2,\n",
    "                                                       (UNIT * y) + UNIT / 2,\n",
    "                                                       image=self.shapes[2])\n",
    "\n",
    "            self.goal.append(temp['figure'])\n",
    "\n",
    "\n",
    "        elif reward < 0:\n",
    "            temp['direction'] = -1\n",
    "            temp['reward'] = reward\n",
    "            temp['figure'] = self.canvas.create_image((UNIT * x) + UNIT / 2,\n",
    "                                                      (UNIT * y) + UNIT / 2,\n",
    "                                                      image=self.shapes[1])\n",
    "\n",
    "        temp['coords'] = self.canvas.coords(temp['figure'])\n",
    "        temp['state'] = state\n",
    "        self.rewards.append(temp)\n",
    "\n",
    "    # new methods\n",
    "    def check_if_reward(self, state):\n",
    "        check_list = dict()\n",
    "        check_list['if_goal'] = False\n",
    "        rewards = 0\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            if reward['state'] == state:\n",
    "                rewards += reward['reward']\n",
    "                if reward['reward'] == 1:\n",
    "                    check_list['if_goal'] = True\n",
    "\n",
    "        check_list['rewards'] = rewards\n",
    "\n",
    "        return check_list\n",
    "\n",
    "    def coords_to_state(self, coords):\n",
    "        x = int((coords[0] - UNIT / 2) / UNIT)\n",
    "        y = int((coords[1] - UNIT / 2) / UNIT)\n",
    "        return [x, y]\n",
    "\n",
    "    def reset(self):\n",
    "        self.update()\n",
    "        time.sleep(0.5)\n",
    "        x, y = self.canvas.coords(self.rectangle)\n",
    "        self.canvas.move(self.rectangle, UNIT / 2 - x, UNIT / 2 - y)\n",
    "        self.reset_reward()\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.counter += 1\n",
    "        self.render()\n",
    "\n",
    "        if self.counter % 2 == 1:\n",
    "            self.rewards = self.move_rewards()\n",
    "\n",
    "        next_coords = self.move(self.rectangle, action)\n",
    "        check = self.check_if_reward(self.coords_to_state(next_coords))\n",
    "        done = check['if_goal']\n",
    "        reward = check['rewards']\n",
    "\n",
    "        self.canvas.tag_raise(self.rectangle)\n",
    "\n",
    "        s_ = self.get_state()\n",
    "\n",
    "        return s_, reward, done\n",
    "\n",
    "    def get_state(self):\n",
    "\n",
    "        location = self.coords_to_state(self.canvas.coords(self.rectangle))\n",
    "        agent_x = location[0]\n",
    "        agent_y = location[1]\n",
    "\n",
    "        states = list()\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            reward_location = reward['state']\n",
    "            states.append(reward_location[0] - agent_x)\n",
    "            states.append(reward_location[1] - agent_y)\n",
    "            if reward['reward'] < 0:\n",
    "                states.append(-1)\n",
    "                states.append(reward['direction'])\n",
    "            else:\n",
    "                states.append(1)\n",
    "\n",
    "        return states\n",
    "\n",
    "    def move_rewards(self):\n",
    "        new_rewards = []\n",
    "        for temp in self.rewards:\n",
    "            if temp['reward'] == 1:\n",
    "                new_rewards.append(temp)\n",
    "                continue\n",
    "            temp['coords'] = self.move_const(temp)\n",
    "            temp['state'] = self.coords_to_state(temp['coords'])\n",
    "            new_rewards.append(temp)\n",
    "        return new_rewards\n",
    "\n",
    "    def move_const(self, target):\n",
    "\n",
    "        s = self.canvas.coords(target['figure'])\n",
    "\n",
    "        base_action = np.array([0, 0])\n",
    "\n",
    "        if s[0] == (WIDTH - 1) * UNIT + UNIT / 2:\n",
    "            target['direction'] = 1\n",
    "        elif s[0] == UNIT / 2:\n",
    "            target['direction'] = -1\n",
    "\n",
    "        if target['direction'] == -1:\n",
    "            base_action[0] += UNIT\n",
    "        elif target['direction'] == 1:\n",
    "            base_action[0] -= UNIT\n",
    "\n",
    "        if (target['figure'] is not self.rectangle\n",
    "           and s == [(WIDTH - 1) * UNIT, (HEIGHT - 1) * UNIT]):\n",
    "            base_action = np.array([0, 0])\n",
    "\n",
    "        self.canvas.move(target['figure'], base_action[0], base_action[1])\n",
    "\n",
    "        s_ = self.canvas.coords(target['figure'])\n",
    "\n",
    "        return s_\n",
    "\n",
    "    def move(self, target, action):\n",
    "        s = self.canvas.coords(target)\n",
    "\n",
    "        base_action = np.array([0, 0])\n",
    "\n",
    "        if action == 0:  # 상\n",
    "            if s[1] > UNIT:\n",
    "                base_action[1] -= UNIT\n",
    "        elif action == 1:  # 하\n",
    "            if s[1] < (HEIGHT - 1) * UNIT:\n",
    "                base_action[1] += UNIT\n",
    "        elif action == 2:  # 우\n",
    "            if s[0] < (WIDTH - 1) * UNIT:\n",
    "                base_action[0] += UNIT\n",
    "        elif action == 3:  # 좌\n",
    "            if s[0] > UNIT:\n",
    "                base_action[0] -= UNIT\n",
    "\n",
    "        self.canvas.move(target, base_action[0], base_action[1])\n",
    "\n",
    "        s_ = self.canvas.coords(target)\n",
    "\n",
    "        return s_\n",
    "\n",
    "    def render(self):\n",
    "        # 게임 속도 조정\n",
    "        time.sleep(self.render_speed)\n",
    "        self.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage25\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 90\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(entropy)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# 환경과 에이전트 생성\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_speed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     state_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     92\u001b[0m     action_space \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n",
      "Cell \u001b[1;32mIn[31], line 28\u001b[0m, in \u001b[0;36mEnv.__init__\u001b[1;34m(self, render_speed)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 인스턴스 변수로 이미지 저장\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_images()\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_canvas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[31], line 57\u001b[0m, in \u001b[0;36mEnv._build_canvas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 캔버스에 이미지 추가\u001b[39;00m\n\u001b[0;32m     56\u001b[0m x, y \u001b[38;5;241m=\u001b[39m UNIT\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, UNIT\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrectangle \u001b[38;5;241m=\u001b[39m \u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m canvas\u001b[38;5;241m.\u001b[39mpack()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m canvas\n",
      "File \u001b[1;32mc:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:2819\u001b[0m, in \u001b[0;36mCanvas.create_image\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m   2817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   2818\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create image item with coordinates x1,y1.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fkfma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:2805\u001b[0m, in \u001b[0;36mCanvas._create\u001b[1;34m(self, itemType, args, kw)\u001b[0m\n\u001b[0;32m   2803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2804\u001b[0m     cnf \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mgetint(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitemType\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage25\" doesn't exist"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "# from environment import Env\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# 상태가 입력, 각 행동의 확률이 출력인 인공신경망 생성\n",
    "class REINFORCE(tf.keras.Model):\n",
    "    def __init__(self, action_size):\n",
    "        super(REINFORCE, self).__init__()\n",
    "        self.fc1 = Dense(24, activation='relu')\n",
    "        self.fc2 = Dense(24, activation='relu')\n",
    "        self.fc_out = Dense(action_size, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        policy = self.fc_out(x)\n",
    "        return policy\n",
    "\n",
    "\n",
    "# 그리드월드 예제에서의 REINFORCE 에이전트\n",
    "class REINFORCEAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # 상태의 크기와 행동의 크기 정의\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # REINFORCE 하이퍼 파라메터\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.model = REINFORCE(self.action_size)\n",
    "        self.optimizer = Adam(lr=self.learning_rate)\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "\n",
    "    # 정책신경망으로 행동 선택\n",
    "    def get_action(self, state):\n",
    "        policy = self.model(state)[0]\n",
    "        policy = np.array(policy)\n",
    "        return np.random.choice(self.action_size, 1, p=policy)[0]\n",
    "\n",
    "    # 반환값 계산\n",
    "    def discount_rewards(self, rewards):\n",
    "        discounted_rewards = np.zeros_like(rewards)\n",
    "        running_add = 0\n",
    "        for t in reversed(range(0, len(rewards))):\n",
    "            running_add = running_add * self.discount_factor + rewards[t]\n",
    "            discounted_rewards[t] = running_add\n",
    "        return discounted_rewards\n",
    "\n",
    "    # 한 에피소드 동안의 상태, 행동, 보상을 저장\n",
    "    def append_sample(self, state, action, reward):\n",
    "        self.states.append(state[0])\n",
    "        self.rewards.append(reward)\n",
    "        act = np.zeros(self.action_size)\n",
    "        act[action] = 1\n",
    "        self.actions.append(act)\n",
    "\n",
    "    # 정책신경망 업데이트\n",
    "    def train_model(self):\n",
    "        discounted_rewards = np.float32(self.discount_rewards(self.rewards))\n",
    "        discounted_rewards -= np.mean(discounted_rewards)\n",
    "        discounted_rewards /= np.std(discounted_rewards)\n",
    "        \n",
    "        # 크로스 엔트로피 오류함수 계산\n",
    "        model_params = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model_params)\n",
    "            policies = self.model(np.array(self.states))\n",
    "            actions = np.array(self.actions)\n",
    "            action_prob = tf.reduce_sum(actions * policies, axis=1)\n",
    "            cross_entropy = - tf.math.log(action_prob + 1e-5)\n",
    "            loss = tf.reduce_sum(cross_entropy * discounted_rewards)\n",
    "            entropy = - policies * tf.math.log(policies)\n",
    "\n",
    "        # 오류함수를 줄이는 방향으로 모델 업데이트\n",
    "        grads = tape.gradient(loss, model_params)\n",
    "        self.optimizer.apply_gradients(zip(grads, model_params))\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "        return np.mean(entropy)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 환경과 에이전트 생성\n",
    "    env = Env(render_speed=0.01)\n",
    "    state_size = 15\n",
    "    action_space = [0, 1, 2, 3, 4]\n",
    "    action_size = len(action_space)\n",
    "    agent = REINFORCEAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    EPISODES = 200\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        # env 초기화\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "            # 현재 상태에 대한 행동 선택\n",
    "            action = agent.get_action(state)\n",
    "\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행 후 샘플 수집\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            agent.append_sample(state, action, reward)\n",
    "            score += reward\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # 에피소드마다 정책신경망 업데이트\n",
    "                entropy = agent.train_model()\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "                print(\"episode: {:3d} | score: {:3d} | entropy: {:.3f}\".format(\n",
    "                      e, score, entropy))\n",
    "\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.xlabel(\"episode\")\n",
    "                pylab.ylabel(\"score\")\n",
    "                pylab.savefig(\"./save_graph/graph.png\")\n",
    "                \n",
    "\n",
    "        # 100 에피소드마다 모델 저장\n",
    "        if e % 100 == 0:\n",
    "            agent.model.save_weights('save_model/model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
